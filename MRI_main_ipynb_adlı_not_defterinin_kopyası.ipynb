{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Konstvv/DL_MRI_reconstriction/blob/main/MRI_main_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO list:\n",
        "1. Find the dataset (High-quality MRI images)\n",
        "* small dataset - https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
        "* large dataset - https://fastmri.med.nyu.edu/ (need to request the access)\n",
        "* Something else?\n",
        "\n",
        "2. Preprocess the data\n",
        "\n",
        " 2.1 HQ images -> make them noisy\n",
        "\n",
        " * White noise - every pixel would get a SMALL random increment\n",
        " * Gaussian blur - https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html\n",
        "\n",
        " 2.2 (maybe optional, depends on dataset size) Data augmentation\n",
        " * Rotation (saving the original size)\n",
        " * Zoom\n",
        " * Mirror\n",
        "\n",
        "Training sample - pair of images (clean and corrupted images: label and sample)\n",
        "\n",
        "3. Creation of the model\n",
        "\n",
        "  * Supervised learning paradigm\n",
        "  * Baseline model - CNN architecture (dims of input and output are the same)\n",
        "  * Compare the output to the orginal image:\n",
        "      * PSNR(Peak Signal-to-Noise Ratio)\n",
        "      * SSIM\n",
        "  * Overview of the models: https://arxiv.org/pdf/1912.13171.pdf\n",
        "  * Brain MRI model: https://aapm.onlinelibrary.wiley.com/doi/epdf/10.1002/acm2.13758\n",
        "\n",
        "  * General overview: https://towardsai.net/p/deep-learning/image-de-noising-using-deep-learning\n",
        "\n",
        "4. Tuning and testing\n"
      ],
      "metadata": {
        "id": "VjMl2ebMw1ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Part 1\n",
        "# Dataset import\n",
        "# Upload it to Google Drive\n",
        "# Fetch the data Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIAFE8VZyDUg",
        "outputId": "39e43207-9c76-4f87-bd84-38652a013a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!pip install fastmri\n",
        "import h5py\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import fastmri\n",
        "from fastmri.data import transforms as T\n",
        "import os\n",
        "from fastmri.data.subsample import RandomMaskFunc\n",
        "filepath = '/content/drive/MyDrive/multicoil_test/multicoil_test'\n",
        "import cv2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def show_coils(data, slice_nums, cmap=None):\n",
        "    fig = plt.figure()\n",
        "    for integer, num in enumerate(slice_nums):\n",
        "        plt.subplot(1, len(slice_nums), integer + 1)\n",
        "        plt.imshow(data[num], cmap=cmap)\n",
        "\n",
        "real_images = []\n",
        "for filename in os.listdir(filepath):\n",
        "\n",
        "\n",
        "    file_name = os.path.join(filepath, filename)\n",
        "    sz = os.stat(file_name)\n",
        "    print(sz.st_size)\n",
        "    hf = h5py.File(file_name, 'r')\n",
        "    print('Keys:', list(hf.keys()))\n",
        "    print('Attrs:', dict(hf.attrs))\n",
        "    volume_kspace = hf['kspace'][()]\n",
        "    print(volume_kspace.dtype)\n",
        "    print(volume_kspace.shape)\n",
        "\n",
        "    for i in range(0, volume_kspace.shape[0]):\n",
        "        slice_kspace = volume_kspace[i]\n",
        "\n",
        "    # show_coils(np.log(np.abs(slice_kspace) + 1e-9), [0, 5, 10])\n",
        "\n",
        "        slice_kspace2 = T.to_tensor(slice_kspace)  # Convert from numpy array to pytorch tensor\n",
        "        slice_image = fastmri.ifft2c(slice_kspace2)  # Apply Inverse Fourier Transform to get the complex image\n",
        "        slice_image_abs = fastmri.complex_abs(slice_image)  # Compute absolute value to get a real image\n",
        "\n",
        "    # show_coils(slice_image_abs, [0, 5, 10], cmap='gray')\n",
        "        slice_image_rss = fastmri.rss(slice_image_abs, dim=0)\n",
        "\n",
        "        mask_func = RandomMaskFunc(center_fractions=[0.04], accelerations=[8])  # Create the mask function object\n",
        "        masked_kspace, mask, _ = T.apply_mask(slice_kspace2, mask_func)  # Apply the mask to k-space\n",
        "\n",
        "        sampled_image = fastmri.ifft2c(masked_kspace)  # Apply Inverse Fourier Transform to get the complex image\n",
        "        sampled_image_abs = fastmri.complex_abs(sampled_image)  # Compute absolute value to get a real image\n",
        "        sampled_image_rss = fastmri.rss(sampled_image_abs, dim=0)\n",
        "\n",
        "        real_images.append(np.abs(sampled_image_rss.numpy()))  # Append the real image to the list\n",
        "\n",
        "\n",
        "        print(\"Added\")\n",
        "\n",
        "for i in real_images:\n",
        "\n",
        "    plt.imshow(i, cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mm3C9H_b48fB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "622ad79e-0dfc-4b1f-c86e-701161263bde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9B2BVVW5W_0",
        "outputId": "2506d4a5-b90d-4641-f61f-6b9f5114f7fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastmri in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from fastmri) (1.23.5)\n",
            "Requirement already satisfied: scikit-image>=0.16.2 in /usr/local/lib/python3.10/dist-packages (from fastmri) (0.19.3)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from fastmri) (0.15.2+cu118)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fastmri) (2.0.1+cu118)\n",
            "Requirement already satisfied: runstats>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fastmri) (2.0.0)\n",
            "Requirement already satisfied: pytorch-lightning>=1.4 in /usr/local/lib/python3.10/dist-packages (from fastmri) (2.0.9)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from fastmri) (3.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from fastmri) (6.0.1)\n",
            "Requirement already satisfied: torchmetrics>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from fastmri) (1.2.0)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from fastmri) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->fastmri) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->fastmri) (2023.3.post1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.4->fastmri) (4.66.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.4->fastmri) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.4->fastmri) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.4->fastmri) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.4->fastmri) (0.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.2->fastmri) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.2->fastmri) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.2->fastmri) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.2->fastmri) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.2->fastmri) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.2->fastmri) (1.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastmri) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastmri) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastmri) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastmri) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->fastmri) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->fastmri) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.8.1->fastmri) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (3.8.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->fastmri) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->fastmri) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.1->fastmri) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.1->fastmri) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.1->fastmri) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.8.1->fastmri) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->fastmri) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.4->fastmri) (1.3.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6045586433fe>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mreal_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/multicoil_test/multicoil_test'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomContrast, RandomZoom\n",
        "\n",
        "class NoiseLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, noise_type='gauss'):\n",
        "    super(NoiseLayer, self).__init__()\n",
        "    self.noise_type = noise_type\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    pass\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self.noise_type == \"gauss\":\n",
        "        mean = 0\n",
        "        var = 0.1\n",
        "        gauss = np.random.normal(mean, var**0.5, inputs.shape)\n",
        "        gauss = gauss.reshape(*inputs.shape)\n",
        "        noisy = inputs + gauss\n",
        "        return noisy\n",
        "    elif self.noise_type == \"poisson\":\n",
        "        peak = 5\n",
        "        noisy = np.random.poisson(inputs * peak) / float(peak)\n",
        "        return noisy\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal_and_vertical\"),\n",
        "    RandomZoom(0.1, fill_mode='nearest'),\n",
        "    RandomRotation(0.2, fill_mode='nearest'),\n",
        "    RandomContrast(0.3),\n",
        "    NoiseLayer(noise_type='poisson')])\n",
        "\n",
        "def noisy_data(real_images):\n",
        "    real_images = [cv2.resize(img, (640, 320)) for img in images]\n",
        "\n",
        "    augmented_images = data_augmentation(images)\n",
        "    noisy_images = tf.clip_by_value(augmented_images, 0., 1.)\n",
        "\n",
        "    return noisy_images"
      ],
      "metadata": {
        "id": "_u8RroSOdZgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.astype('float32') / 255.\n",
        "test_data = test_data.astype('float32') / 255.\n",
        "\n",
        "noisy_train = noisy_data(train_data)\n",
        "noisy_test = noisy_data(test_data)"
      ],
      "metadata": {
        "id": "H1Mom0TZRPUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Part 3\n",
        "# Model architechture\n",
        "# Keras to create baseline CNN model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input = layers.Input(shape=(640, 320, 1))\n",
        "\n",
        "# Encoder\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(input, x)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "XHGojx4P5_gR",
        "outputId": "fd616c32-ec29-4ee1-d162-a9eaa18d32a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2D  (None, 14, 14, 32)        9248      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2D  (None, 28, 28, 32)        9248      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28353 (110.75 KB)\n",
            "Trainable params: 28353 (110.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(\n",
        "    x=noisy_train,\n",
        "    y=train_data,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_test, test_data),\n",
        ")"
      ],
      "metadata": {
        "id": "EsHLkvwFR5Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Part 4\n",
        "# Evaluation and testing"
      ],
      "metadata": {
        "id": "jJTS9j486Ogv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}